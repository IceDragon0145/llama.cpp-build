# llama.cpp-build
Automatically build [ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp) with CUDA.
