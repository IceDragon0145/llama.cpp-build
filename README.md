# llama.cpp-build
Automatically build llama.cpp with CUDA.
